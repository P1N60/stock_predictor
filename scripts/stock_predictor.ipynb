{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Installation (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -Ur requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gradio as gr\n",
    "import ast\n",
    "import warnings\n",
    "from time import sleep\n",
    "from data_processer import *\n",
    "from stockdex import Ticker\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from model import MLPWrapper\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_list = input(\"Symbols: ('simple', 'filtered' or 'all')\") # 'simple' or 'all'. simple are the tickers from the screener notebook and all are all of the tickers in 'filtered_tickers'. You may also an 'Int' to get a % amount of random tickers from 'all'\n",
    "if symbol_list:\n",
    "    build_new_dataset = True\n",
    "else:\n",
    "    build_new_dataset = False\n",
    "    symbol_list = 'filtered'\n",
    "minimum_feature_threshold = 0.6\n",
    "outlier = 3\n",
    "iterations = input(\"Iterations eg. '10', '20', '30'\")\n",
    "if iterations:\n",
    "    iterations = ast.literal_eval(iterations)\n",
    "    train_new_model = True\n",
    "    search_params = {\n",
    "            \"hidden_layer_amount\": Integer(2, 20),\n",
    "            \"neuron_amount\": Integer(20, 4000),\n",
    "            \"warm_start\": Categorical([False, True]),\n",
    "            \"activation\": Categorical(['identity', 'logistic', 'tanh', 'relu']),\n",
    "            \"solver\": Categorical(['sgd', 'adam', 'lbfgs']),\n",
    "            \"alpha\": Real(0.000001, 1),\n",
    "            \"learning_rate_init\": Real(0.00001, 0.1),\n",
    "            \"power_t\": Real(0.0001, 100),\n",
    "            \"momentum\": Real(0.0001, 100),\n",
    "            \"validation_fraction\": Real(0.05, 0.20),\n",
    "            \"beta_1\": Real(0.001, 10),\n",
    "            \"beta_2\": Real(0.0001, 100),\n",
    "            \"epsilon\": Real(0.0000000001, 0.000001),}\n",
    "    cross_validations = 2  # will be set to 3 if not specified\n",
    "    verticle_jobs = 1 #'-1' for max\n",
    "else:\n",
    "    train_new_model = False\n",
    "if build_new_dataset or train_new_model:\n",
    "    debugging = {'True': True, 'False': False}.get(input('Debug? (Bool)'))\n",
    "else:\n",
    "    debugging = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MATAS.CO', 'TRIFOR.CO', 'RNMBY', 'SAABF', 'BCKIY', 'BAESY',\n",
       "       'IVSO.ST', 'NSKFF', 'GMAB', 'GN.CO', 'NVDA', 'LLY', 'DANSKE.CO',\n",
       "       'CARL-B.CO', 'MAERSK-B.CO', 'RBREW.CO', 'ISS.CO', 'DSV.CO',\n",
       "       'SCHO.CO', 'NETC.CO', 'JYSK.CO', 'ABBN.SW', 'TER', 'PARKEN.CO',\n",
       "       'NFLX', 'STG.CO', 'NOVO-B.CO', 'EQNR', 'NKT.CO', 'TSLA', 'HEM.ST',\n",
       "       'DEMANT.CO', 'BAVA.CO ', 'BABA', 'JD', 'PDD', 'BIDU', 'NTES', 'WB',\n",
       "       'IQ', 'SYDB.CO', 'UBER', 'COLO-B.CO'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols = pd.read_csv('../data/simple_tickers.csv')['Ticker'].tolist()\n",
    "if symbol_list == 'filtered':\n",
    "    symbols = symbols + pd.read_csv('../data/filtered_tickers.csv')['Ticker'].tolist()\n",
    "elif symbol_list == 'all':\n",
    "    symbols = symbols + pd.read_csv('../data/tickers.csv')['Ticker'].tolist()\n",
    "elif symbol_list.isdigit():\n",
    "    all_symbols = pd.read_csv('../data/tickers.csv')['Ticker'].tolist()\n",
    "    num_symbols = max(1, round(len(all_symbols) * (int(symbol_list) / 100)))  \n",
    "    symbols = symbols + pd.read_csv(\"../data/filtered_tickers.csv\")[\"Ticker\"].tolist()\n",
    "    symbols = symbols + np.random.choice(all_symbols, num_symbols, replace=False).tolist()\n",
    "\n",
    "symbols = pd.Series(symbols).unique()\n",
    "symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATAS.CO\n",
      "list index out of range\n",
      "TRIFOR.CO\n",
      "list index out of range\n",
      "RNMBY\n",
      "list index out of range\n",
      "SAABF\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(symbol)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     search_results \u001b[38;5;241m=\u001b[39m search_assets(query\u001b[38;5;241m=\u001b[39msymbol, limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStock\u001b[39m\u001b[38;5;124m\"\u001b[39m, exchange\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNASDAQ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     investing_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(search_results[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;66;03m# Assuming the first entry is the desired one (top result in Investing.com)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     data \u001b[38;5;241m=\u001b[39m historical_data(investing_id\u001b[38;5;241m=\u001b[39minvesting_id, from_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m09/01/2015\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10/01/2025\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/investiny/search.py:42\u001b[0m, in \u001b[0;36msearch_assets\u001b[0;34m(query, limit, type, exchange)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Search any available asset at Investing.com.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    A list of dictionaries with the search results from Investing.com.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query,\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit\u001b[39m\u001b[38;5;124m\"\u001b[39m: limit,\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexchange\u001b[39m\u001b[38;5;124m\"\u001b[39m: exchange \u001b[38;5;28;01mif\u001b[39;00m exchange \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m }\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m request_to_investing(endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch\u001b[39m\u001b[38;5;124m\"\u001b[39m, params\u001b[38;5;241m=\u001b[39mparams)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/investiny/utils.py:34\u001b[0m, in \u001b[0;36mrequest_to_investing\u001b[0;34m(endpoint, params)\u001b[0m\n\u001b[1;32m     25\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://tvc6.investing.com/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muuid4()\u001b[38;5;241m.\u001b[39mhex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/0/0/0/0/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m }\n\u001b[0;32m---> 34\u001b[0m r \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mget(url, params\u001b[38;5;241m=\u001b[39mparams, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest to Investing.com API failed with error code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_api.py:189\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, headers, cookies, auth, proxies, follow_redirects, cert, verify, timeout, trust_env)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\n\u001b[1;32m    168\u001b[0m     url: URLTypes,\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m     trust_env: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    Sends a `GET` request.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    on this function, as `GET` requests should not include a request body.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    191\u001b[0m         url,\n\u001b[1;32m    192\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    193\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    194\u001b[0m         cookies\u001b[38;5;241m=\u001b[39mcookies,\n\u001b[1;32m    195\u001b[0m         auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m    196\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    197\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    198\u001b[0m         cert\u001b[38;5;241m=\u001b[39mcert,\n\u001b[1;32m    199\u001b[0m         verify\u001b[38;5;241m=\u001b[39mverify,\n\u001b[1;32m    200\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    201\u001b[0m         trust_env\u001b[38;5;241m=\u001b[39mtrust_env,\n\u001b[1;32m    202\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_api.py:100\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, params, content, data, files, json, headers, cookies, auth, proxies, timeout, follow_redirects, verify, cert, trust_env)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03mSends an HTTP request.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Client(\n\u001b[1;32m     93\u001b[0m     cookies\u001b[38;5;241m=\u001b[39mcookies,\n\u001b[1;32m     94\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m     trust_env\u001b[38;5;241m=\u001b[39mtrust_env,\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    101\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    102\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    103\u001b[0m         content\u001b[38;5;241m=\u001b[39mcontent,\n\u001b[1;32m    104\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    105\u001b[0m         files\u001b[38;5;241m=\u001b[39mfiles,\n\u001b[1;32m    106\u001b[0m         json\u001b[38;5;241m=\u001b[39mjson,\n\u001b[1;32m    107\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    108\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    109\u001b[0m         auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m    110\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    111\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_client.py:821\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    806\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    808\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    809\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    810\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    819\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    820\u001b[0m )\n\u001b[0;32m--> 821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(request, auth\u001b[38;5;241m=\u001b[39mauth, follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_client.py:908\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    900\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    904\u001b[0m )\n\u001b[1;32m    906\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 908\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m    909\u001b[0m     request,\n\u001b[1;32m    910\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m    911\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    912\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m    913\u001b[0m )\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_client.py:936\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    933\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m    937\u001b[0m         request,\n\u001b[1;32m    938\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    939\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m    940\u001b[0m     )\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_client.py:973\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    971\u001b[0m     hook(request)\n\u001b[0;32m--> 973\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_client.py:1009\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1005\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1006\u001b[0m     )\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1009\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1013\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_transports/default.py:218\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    205\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    206\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    207\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    216\u001b[0m )\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 218\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    223\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    224\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    225\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    226\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    227\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:253\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_closed(status)\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:237\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# up as HTTP/1.1.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool_lock:\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;66;03m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;66;03m# status so that the request becomes queued again.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection.py:90\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:112\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp11.response_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:91\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request_body(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp11.receive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, request, kwargs\n\u001b[1;32m     85\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m     86\u001b[0m     (\n\u001b[1;32m     87\u001b[0m         http_version,\n\u001b[1;32m     88\u001b[0m         status,\n\u001b[1;32m     89\u001b[0m         reason_phrase,\n\u001b[1;32m     90\u001b[0m         headers,\n\u001b[0;32m---> 91\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     92\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     93\u001b[0m         http_version,\n\u001b[1;32m     94\u001b[0m         status,\n\u001b[1;32m     95\u001b[0m         reason_phrase,\n\u001b[1;32m     96\u001b[0m         headers,\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    100\u001b[0m     status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m    101\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     },\n\u001b[1;32m    108\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:155\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    152\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:191\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    188\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 191\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    193\u001b[0m     )\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/backends/sync.py:28\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/ssl.py:1233\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1230\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1232\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/ssl.py:1106\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from investiny import historical_data, search_assets\n",
    "\n",
    "for symbol in symbols:\n",
    "    print(symbol)\n",
    "    try:\n",
    "        search_results = search_assets(query=symbol, limit=1, type=\"Stock\", exchange=\"NASDAQ\")\n",
    "        investing_id = int(search_results[0][\"ticker\"]) # Assuming the first entry is the desired one (top result in Investing.com)\n",
    "        data = historical_data(investing_id=investing_id, from_date=\"09/01/2015\", to_date=\"10/01/2025\")\n",
    "        display(data)\n",
    "    except Exception as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download annual financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m stock \u001b[38;5;241m=\u001b[39m Stock(symbol)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m     ticker_df \u001b[38;5;241m=\u001b[39m Stock(symbol)\u001b[38;5;241m.\u001b[39mget_data_key()\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ticker_df\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mround\u001b[39m(\u001b[38;5;241m29\u001b[39m \u001b[38;5;241m*\u001b[39m minimum_feature_threshold):\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m symbol \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m filtered_pd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist():\n",
      "File \u001b[0;32m~/Documents/GitHub/Uni/side_projects/stock_predictor/scripts/data_processer.py:30\u001b[0m, in \u001b[0;36mStock.get_data_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m     row_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3M Future Change\u001b[39m\u001b[38;5;124m\"\u001b[39m], row_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6M Future Change\u001b[39m\u001b[38;5;124m\"\u001b[39m], row_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m9M Future Change\u001b[39m\u001b[38;5;124m\"\u001b[39m], row_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1Y Future Change\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan, np\u001b[38;5;241m.\u001b[39mnan, np\u001b[38;5;241m.\u001b[39mnan, np\u001b[38;5;241m.\u001b[39mnan\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     price_data \u001b[38;5;241m=\u001b[39m yf\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbol, period\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, rounding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     31\u001b[0m     got_price \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     day_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/yfinance/utils.py:92\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[0;32m---> 92\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     94\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/yfinance/multi.py:167\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(tickers, start, end, actions, threads, ignore_tz, group_by, auto_adjust, back_adjust, repair, keepna, progress, period, interval, prepost, proxy, rounding, timeout, session, multi_level_index)\u001b[0m\n\u001b[1;32m    160\u001b[0m         _download_one_threaded(ticker, period\u001b[38;5;241m=\u001b[39mperiod, interval\u001b[38;5;241m=\u001b[39minterval,\n\u001b[1;32m    161\u001b[0m                                start\u001b[38;5;241m=\u001b[39mstart, end\u001b[38;5;241m=\u001b[39mend, prepost\u001b[38;5;241m=\u001b[39mprepost,\n\u001b[1;32m    162\u001b[0m                                actions\u001b[38;5;241m=\u001b[39mactions, auto_adjust\u001b[38;5;241m=\u001b[39mauto_adjust,\n\u001b[1;32m    163\u001b[0m                                back_adjust\u001b[38;5;241m=\u001b[39mback_adjust, repair\u001b[38;5;241m=\u001b[39mrepair, keepna\u001b[38;5;241m=\u001b[39mkeepna,\n\u001b[1;32m    164\u001b[0m                                progress\u001b[38;5;241m=\u001b[39m(progress \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    165\u001b[0m                                rounding\u001b[38;5;241m=\u001b[39mrounding, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shared\u001b[38;5;241m.\u001b[39m_DFS) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(tickers):\n\u001b[0;32m--> 167\u001b[0m         _time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# download synchronously\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, ticker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tickers):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if build_new_dataset:\n",
    "    df = pd.DataFrame()\n",
    "    filtered_pd = pd.read_csv('../data/filtered_tickers.csv')\n",
    "    for symbol in tqdm(symbols, smoothing=0):\n",
    "        ticker_df = pd.DataFrame()\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        stock = Stock(symbol)\n",
    "        try:\n",
    "            ticker_df = Stock(symbol).get_data_key()\n",
    "            if ticker_df.isna().sum().sum() < round(29 * minimum_feature_threshold):\n",
    "                if symbol not in filtered_pd['Ticker'].tolist():\n",
    "                    filtered_pd = pd.concat([filtered_pd, pd.DataFrame([{'Ticker': symbol}])])\n",
    "                imputer = SimpleImputer()\n",
    "                for column in ticker_df.columns.drop(['Ticker', 'Name', 'Date', '3M Future Change', '6M Future Change', '9M Future Change', '1Y Future Change', 'Sector', 'Industry']):\n",
    "                    if not ticker_df[column].isna().all():\n",
    "                        ticker_df[column] = imputer.fit_transform(ticker_df[[column]])\n",
    "            else:\n",
    "                if symbol in filtered_pd['Ticker'].tolist():\n",
    "                    filtered_pd = filtered_pd[filtered_pd['Ticker'] != symbol]\n",
    "                    if debugging:\n",
    "                        print(f'Removed {symbol} from filtered tickers. Datapoints: {ticker_df.isna().sum().sum()}, Needed: {round(29 * minimum_feature_threshold)}')\n",
    "                continue\n",
    "            df = pd.concat([df, ticker_df], ignore_index=True)\n",
    "        except Exception as error:\n",
    "            if symbol in filtered_pd['Ticker'].tolist():\n",
    "                filtered_pd = filtered_pd[filtered_pd['Ticker'] != symbol]\n",
    "                if debugging:\n",
    "                    print(f'Removed {symbol} from filtered tickers because an exception was raised \\n {error}')\n",
    "            else:\n",
    "                if debugging:\n",
    "                    print(f\"{symbol}: exception raised: {error}\")\n",
    "            continue\n",
    "    filtered_pd.to_csv('../data/filtered_tickers.csv', index=False)\n",
    "    df.to_csv('../data/earnings_data.csv', index=False)\n",
    "else:\n",
    "    df = pd.read_csv('../data/earnings_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debugging:\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impution and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer()\n",
    "scaler = StandardScaler()\n",
    "for column in df.columns.drop(['Ticker', 'Name', 'Date', '3M Future Change', '6M Future Change', '9M Future Change', '1Y Future Change', 'Sector', 'Industry']):\n",
    "    df[column] = imputer.fit_transform(df[[column]])\n",
    "    scaler.fit(df[[column]])\n",
    "    df[column] = scaler.transform(df[[column]])\n",
    "\n",
    "le = LabelEncoder()\n",
    "for column in ['Sector', 'Industry']:\n",
    "    df[column] = df[column].astype(str)\n",
    "    le.fit(df[column])\n",
    "    df[column] = le.transform(df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "train_data = pd.DataFrame()\n",
    "for i in tqdm(range(int(len(df) / 4)), smoothing=0):\n",
    "    cont = False\n",
    "    for j in range(4):\n",
    "        if (df.loc[j+i*4, \"3M Future Change\"] > outlier or\n",
    "            df.loc[j+i*4, \"6M Future Change\"] > outlier or\n",
    "            df.loc[j+i*4, \"9M Future Change\"] > outlier or\n",
    "            df.loc[j+i*4, \"1Y Future Change\"] > outlier):\n",
    "            cont = True\n",
    "    if cont:\n",
    "        continue\n",
    "    pred_data = pd.concat([pred_data, df.iloc[[i*4]]]) \n",
    "    test_data = pd.concat([test_data, df.iloc[[1+i*4]]])\n",
    "    train_data = pd.concat([train_data, df.iloc[[2+i*4]]])\n",
    "    train_data = pd.concat([train_data, df.iloc[[3+i*4]]])\n",
    "if debugging:\n",
    "    print('Prediction Data:')\n",
    "    display(pred_data)\n",
    "    print(\"Test Data:\")\n",
    "    display(test_data)\n",
    "    print('Training Data:')\n",
    "    display(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Ticker', 'Name', 'Sector', 'Industry', 'Date', '3M Future Change', '6M Future Change', '9M Future Change', '1Y Future Change'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_columns \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSector\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndustry\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3M Future Change\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6M Future Change\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m9M Future Change\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1Y Future Change\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m label_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3M Future Change\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6M Future Change\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m9M Future Change\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1Y Future Change\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m X_pred \u001b[38;5;241m=\u001b[39m pred_data[training_columns]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:7098\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7097\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7098\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7099\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Ticker', 'Name', 'Sector', 'Industry', 'Date', '3M Future Change', '6M Future Change', '9M Future Change', '1Y Future Change'] not found in axis\""
     ]
    }
   ],
   "source": [
    "training_columns = train_data.columns.drop([\"Ticker\", \"Name\", \"Sector\", \"Industry\", \"Date\", '3M Future Change', '6M Future Change', '9M Future Change', '1Y Future Change'])\n",
    "label_columns = ['3M Future Change', '6M Future Change', '9M Future Change', '1Y Future Change']\n",
    "X_pred = pred_data[training_columns]\n",
    "X_test = test_data[training_columns]\n",
    "y_test = test_data[label_columns]\n",
    "X_train = train_data[training_columns]\n",
    "y_train = train_data[label_columns]\n",
    "if debugging:\n",
    "    print(\"X_pred:\")\n",
    "    display(X_pred)\n",
    "    print(\"X_test:\")\n",
    "    display(X_test)\n",
    "    print(\"y_test:\")\n",
    "    display(y_test)\n",
    "    print(\"X_train:\")\n",
    "    display(X_train)\n",
    "    print(\"y_train:\")\n",
    "    display(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_new_model:\n",
    "    opt = BayesSearchCV(\n",
    "        MLPWrapper(),\n",
    "        search_params,\n",
    "        n_iter=iterations,\n",
    "        random_state=42,\n",
    "        cv=cross_validations\n",
    "    )\n",
    "\n",
    "    opt.fit(X_train, y_train.values)\n",
    "    print(f\"Best parameters: {opt.best_params_}\")\n",
    "    model = opt.best_estimator_\n",
    "    \n",
    "    # model = MLPRegressor(\n",
    "    #     hidden_layer_sizes=hidden_layers,\n",
    "    #     learning_rate=\"adaptive\",\n",
    "    #     early_stopping=True,\n",
    "    #     verbose=True,\n",
    "    #     tol=0.00001,\n",
    "    #     n_iter_no_change=round(40000/hidden_layers[0]*4/len(hidden_layers))\n",
    "    # )\n",
    "    # print(f\"iter_no_change: {model.n_iter_no_change}\")\n",
    "    # model.fit(X_train, y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_new_model:\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    for i, target in enumerate(['3M Future Change', '6M Future Change', '9M Future Change', '1Y Future Change']):\n",
    "        y_test_actual = y_test[target]\n",
    "        y_test_pred_target = y_test_pred[:, i]\n",
    "\n",
    "        plt.figure(figsize=(11, 6))\n",
    "        plt.scatter(y_test_actual, y_test_pred_target, alpha=0.7, color='blue', label='Predictions')\n",
    "        plt.plot([y_test_actual.min(), y_test_actual.max()], [y_test_actual.min(), y_test_actual.max()], \n",
    "            color='red', linestyle='--', label='Perfect Fit')\n",
    "        plt.title(f'Predicted vs Actual Values ({target})')\n",
    "        plt.xlabel('Actual Values')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        mae = mean_absolute_error(y_test_actual, y_test_pred_target)\n",
    "        mse = mean_squared_error(y_test_actual, y_test_pred_target)\n",
    "        r2 = r2_score(y_test_actual, y_test_pred_target)\n",
    "\n",
    "        print(f'{target} - R: {r2:.4f}')\n",
    "        print(f'{target} - MSE: {mse:.4f}')\n",
    "        print(f'{target} - MAE: {mae:.4f}')\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    mse = mean_squared_error(y_test, y_test_pred)\n",
    "    r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    print('\\nOverall Scores:')\n",
    "    print(f'Mean - R: {r2:.4f}')\n",
    "    print(f'Mean - MSE: {mse:.4f}')\n",
    "    print(f'Mean - MAE: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_new_model:\n",
    "    test_results = pd.DataFrame({\n",
    "        'R': r2,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'symbol_list': symbol_list,\n",
    "        \"iterations\": iterations,\n",
    "        'hidden_layer_sizes': [model.model.hidden_layer_sizes],\n",
    "        'max_iter': model.model.max_iter,\n",
    "        'n_iter_no_change': model.model.n_iter_no_change,\n",
    "        'learning_rate': model.model.learning_rate,\n",
    "        'learning_rate_init': model.model.learning_rate_init,\n",
    "        'batch_size': model.model.batch_size,\n",
    "        'tol': model.model.tol,\n",
    "        'alpha': model.model.alpha,\n",
    "        'shuffle': model.model.shuffle,\n",
    "    })\n",
    "    test_results.to_csv('../data/test_results.csv', mode='a', index=False)\n",
    "\n",
    "    # save model as new best if results are better than the current one\n",
    "    best_r2 = pd.read_csv('../models/best_model_results.csv').loc[0, 'R']\n",
    "    if r2 > best_r2:\n",
    "        print(f'Old best R: {best_r2}')\n",
    "        print(f'New best R: {r2}')\n",
    "        print('Saving new best model...')\n",
    "        test_results.to_csv('../models/best_model_results.csv', mode='w', index=False)\n",
    "        with open('../models/best_model.pkl','wb') as f:\n",
    "            pickle.dump(model,f)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model R: 0.0289336782535032\n"
     ]
    }
   ],
   "source": [
    "best_r2 = pd.read_csv('../models/best_model_results.csv').loc[0, 'R']\n",
    "\n",
    "with open('../models/best_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    print(f'Best model R: {best_r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Asset Turnover\n- Book Value Per Share\n- Current Ratio\n- Days Sales In Receivables\n- Debt\\/Equity Ratio\n- ...\nFeature names seen at fit time, yet now missing:\n- Accounts Payable\n- Accounts Receivable\n- Accrued Interest Receivable\n- Accumulated Depreciation\n- Additional Paid In Capital\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_pred)):\n\u001b[0;32m----> 5\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_pred\u001b[38;5;241m.\u001b[39miloc[[i]])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m     y_pred_3m, y_pred_6m, y_pred_9m, y_pred_1y \u001b[38;5;241m=\u001b[39m y_pred\n\u001b[1;32m      7\u001b[0m     avg \u001b[38;5;241m=\u001b[39m (y_pred_3m \u001b[38;5;241m+\u001b[39m y_pred_6m \u001b[38;5;241m+\u001b[39m y_pred_9m \u001b[38;5;241m+\u001b[39m y_pred_1y) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1744\u001b[0m, in \u001b[0;36mMLPRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the multi-layer perceptron model.\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \n\u001b[1;32m   1733\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;124;03m    The predicted values.\u001b[39;00m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1744\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1748\u001b[0m, in \u001b[0;36mMLPRegressor._predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Private predict method with optional input validation\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1748\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pass_fast(X, check_input\u001b[38;5;241m=\u001b[39mcheck_input)\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1750\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:204\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the trained model\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03mThis is the same as _forward_pass but does not record the activations\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    The decision function of the samples for each class in the model.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[0;32m--> 204\u001b[0m     X \u001b[38;5;241m=\u001b[39m validate_data(\u001b[38;5;28mself\u001b[39m, X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m], reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# Initialize first layer\u001b[39;00m\n\u001b[1;32m    207\u001b[0m activation \u001b[38;5;241m=\u001b[39m X\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2929\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[1;32m   2846\u001b[0m     _estimator,\n\u001b[1;32m   2847\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2853\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m   2854\u001b[0m ):\n\u001b[1;32m   2855\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[1;32m   2856\u001b[0m \n\u001b[1;32m   2857\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2927\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m   2928\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2929\u001b[0m     _check_feature_names(_estimator, X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[1;32m   2930\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[1;32m   2931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2787\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m   2785\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2787\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Asset Turnover\n- Book Value Per Share\n- Current Ratio\n- Days Sales In Receivables\n- Debt\\/Equity Ratio\n- ...\nFeature names seen at fit time, yet now missing:\n- Accounts Payable\n- Accounts Receivable\n- Accrued Interest Receivable\n- Accumulated Depreciation\n- Additional Paid In Capital\n- ...\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv('../data/earnings_data.csv')\n",
    "\n",
    "results = []\n",
    "for i in range(len(X_pred)):\n",
    "    y_pred = model.predict(X_pred.iloc[[i]])[0]\n",
    "    y_pred_3m, y_pred_6m, y_pred_9m, y_pred_1y = y_pred\n",
    "    avg = (y_pred_3m + y_pred_6m + y_pred_9m + y_pred_1y) / 4\n",
    "    results.append({\n",
    "        'Ticker': df_raw.loc[i*4, 'Ticker'],\n",
    "        'Name': df_raw.loc[i*4, 'Name'],\n",
    "        'mean (%)': avg * 100,\n",
    "        '3m (%)': y_pred_3m * 100,\n",
    "        '6m (%)': y_pred_6m * 100,\n",
    "        '9m (%)': y_pred_9m * 100,\n",
    "        '1y (%)': y_pred_1y * 100\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ticker(ticker_str):\n",
    "    try:\n",
    "        ticker_str = str(ticker_str).upper()\n",
    "        ticker_str = ticker_str.replace(\"'\", \"\")\n",
    "        ticker_str = ticker_str.replace('\"', \"\")\n",
    "        row = results_df[results_df['Ticker'] == ticker_str]\n",
    "        if row.empty:\n",
    "            return (f\"Not enough data for this stock at this moment \\n Try another\", \"\", \"\", \"\", \"\")\n",
    "        row = row.iloc[0]\n",
    "        return (\n",
    "            f\"{row['3m (%)']:.2f}\",\n",
    "            f\"{row['6m (%)']:.2f}\",\n",
    "            f\"{row['9m (%)']:.2f}\",\n",
    "            f\"{row['1y (%)']:.2f}\",\n",
    "            f\"{row['mean (%)']:.2f}\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return (f\"Error: {e}\", \"\", \"\", \"\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://d6f7567b4876962a6e.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d6f7567b4876962a6e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iface = gr.Interface(\n",
    "    fn=predict_ticker,\n",
    "    inputs=gr.Textbox(label=\"Ticker e.g. 'TSLA' or 'NVDA'\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"3 Month Change Prediction (%)\"),\n",
    "        gr.Textbox(label=\"6 Month Change Prediction (%)\"),\n",
    "        gr.Textbox(label=\"9 Month Change Prediction (%)\"),\n",
    "        gr.Textbox(label=\"1 Year Change Prediction (%)\"),\n",
    "        gr.Textbox(label=\"Mean Change Prediction (%)\"),\n",
    "    ],\n",
    "    title=\"Stock Price Prediction Model\",\n",
    "    description=\" \"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
