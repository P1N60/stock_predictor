{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Installation (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -Ur requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victorvj/.local/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gradio as gr\n",
    "import ast\n",
    "import warnings\n",
    "from data_processer import *\n",
    "from stockdex import Ticker\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from model import MLPWrapper\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_list = input(\"Symbols: ('simple', 'filtered' or 'all')\") # 'simple' or 'all'. simple are the tickers from the screener notebook and all are all of the tickers in 'filtered_tickers'. You may also an 'Int' to get a % amount of random tickers from 'all'\n",
    "if symbol_list:\n",
    "    build_new_dataset = True\n",
    "else:\n",
    "    build_new_dataset = False\n",
    "    symbol_list = 'filtered'\n",
    "minimum_feature_threshold = 0.6\n",
    "outlier = 3\n",
    "iterations = input(\"Iterations eg. '10', '20', '30'\")\n",
    "if iterations:\n",
    "    iterations = ast.literal_eval(iterations)\n",
    "    train_new_model = True\n",
    "    search_params = {\n",
    "            \"hidden_layer_amount\": Integer(2, 20),\n",
    "            \"neuron_amount\": Integer(20, 4000),\n",
    "            \"warm_start\": Categorical([False, True]),\n",
    "            \"activation\": Categorical(['identity', 'logistic', 'tanh', 'relu']),\n",
    "            \"solver\": Categorical(['sgd', 'adam', 'lbfgs']),\n",
    "            \"alpha\": Real(0.000001, 1),\n",
    "            \"learning_rate_init\": Real(0.00001, 0.1),\n",
    "            \"power_t\": Real(0.0001, 100),\n",
    "            \"momentum\": Real(0.0001, 100),\n",
    "            \"validation_fraction\": Real(0.05, 0.20),\n",
    "            \"beta_1\": Real(0.001, 10),\n",
    "            \"beta_2\": Real(0.0001, 100),\n",
    "            \"epsilon\": Real(0.0000000001, 0.000001),}\n",
    "    cross_validations = 2  # will be set to 3 if not specified\n",
    "    verticle_jobs = 1 #'-1' for max\n",
    "else:\n",
    "    train_new_model = False\n",
    "if build_new_dataset or train_new_model:\n",
    "    debugging = {'True': True, 'False': False}.get(input('Debug? (Bool)'))\n",
    "else:\n",
    "    debugging = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MATAS.CO', 'TRIFOR.CO', 'RNMBY', 'SAABF', 'BCKIY', 'BAESY',\n",
       "       'IVSO.ST', 'NSKFF', 'GMAB', 'GN.CO', 'NVDA', 'LLY', 'DANSKE.CO',\n",
       "       'CARL-B.CO', 'MAERSK-B.CO', 'RBREW.CO', 'ISS.CO', 'DSV.CO',\n",
       "       'SCHO.CO', 'NETC.CO', 'JYSK.CO', 'ABBN.SW', 'TER', 'PARKEN.CO',\n",
       "       'NFLX', 'STG.CO', 'NOVO-B.CO', 'EQNR', 'NKT.CO', 'TSLA', 'HEM.ST',\n",
       "       'DEMANT.CO', 'BAVA.CO ', 'BABA', 'JD', 'PDD', 'BIDU', 'NTES', 'WB',\n",
       "       'IQ', 'SYDB.CO', 'UBER', 'COLO-B.CO'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols = pd.read_csv('../data/simple_tickers.csv')['Ticker'].tolist()\n",
    "if symbol_list == 'filtered':\n",
    "    symbols = symbols + pd.read_csv('../data/filtered_tickers.csv')['Ticker'].tolist()\n",
    "elif symbol_list == 'all':\n",
    "    symbols = symbols + pd.read_csv('../data/tickers.csv')['Ticker'].tolist()\n",
    "elif symbol_list.isdigit():\n",
    "    all_symbols = pd.read_csv('../data/tickers.csv')['Ticker'].tolist()\n",
    "    num_symbols = max(1, round(len(all_symbols) * (int(symbol_list) / 100)))  \n",
    "    symbols = symbols + pd.read_csv(\"../data/filtered_tickers.csv\")[\"Ticker\"].tolist()\n",
    "    symbols = symbols + np.random.choice(all_symbols, num_symbols, replace=False).tolist()\n",
    "\n",
    "symbols = pd.Series(symbols).unique()\n",
    "symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NoSuchDriverException",
     "evalue": "Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mWebDriverException\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/selenium/webdriver/common/driver_finder.py:67\u001b[39m, in \u001b[36mDriverFinder._binary_paths\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     output = \u001b[43mSeleniumManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbinary_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m Path(output[\u001b[33m\"\u001b[39m\u001b[33mdriver_path\u001b[39m\u001b[33m\"\u001b[39m]).is_file():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/selenium/webdriver/common/selenium_manager.py:47\u001b[39m, in \u001b[36mSeleniumManager.binary_paths\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Determines the locations of the requested assets.\u001b[39;00m\n\u001b[32m     41\u001b[39m \n\u001b[32m     42\u001b[39m \u001b[33;03m:Args:\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[33;03m - args: the commands to send to the selenium manager binary.\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[33;03m:Returns: dictionary of assets and their path\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m args = [\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_binary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)] + args\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logger.getEffectiveLevel() == logging.DEBUG:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/selenium/webdriver/common/selenium_manager.py:94\u001b[39m, in \u001b[36mSeleniumManager._get_binary\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m location \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WebDriverException(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported platform/architecture combination: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msys.platform\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00march\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     96\u001b[39m path = Path(\u001b[34m__file__\u001b[39m).parent.joinpath(location)\n",
      "\u001b[31mWebDriverException\u001b[39m: Message: Unsupported platform/architecture combination: linux/aarch64\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNoSuchDriverException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m tqdm(symbols):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     display(\u001b[43mStock\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_key_financials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/stock_predictor/scripts/data_processer.py:11\u001b[39m, in \u001b[36mStock.get_key_financials\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_key_financials\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTicker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmacrotrends_key_financial_ratios\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/stockdex/macrotrends_interface.py:168\u001b[39m, in \u001b[36mMacrotrendsInterface.macrotrends_key_financial_ratios\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mselenium_interface\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    166\u001b[39m     \u001b[38;5;28mself\u001b[39m.selenium_interface = selenium_interface()\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m soup = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mselenium_interface\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_html_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m data = \u001b[38;5;28mself\u001b[39m._find_table_in_url(\u001b[33m\"\u001b[39m\u001b[33mCurrent Ratio\u001b[39m\u001b[33m\"\u001b[39m, soup)\n\u001b[32m    172\u001b[39m data[\u001b[33m\"\u001b[39m\u001b[33mfield_name\u001b[39m\u001b[33m\"\u001b[39m] = data[\u001b[33m\"\u001b[39m\u001b[33mfield_name\u001b[39m\u001b[33m\"\u001b[39m].apply(\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: re.search(\u001b[33m\"\u001b[39m\u001b[33m>(.*)<\u001b[39m\u001b[33m\"\u001b[39m, x).group(\u001b[32m1\u001b[39m)\n\u001b[32m    174\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/stockdex/selenium_interface.py:44\u001b[39m, in \u001b[36mselenium_interface.get_html_content\u001b[39m\u001b[34m(self, url)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03mMethod to fetch the HTML content of a webpage using Selenium\u001b[39;00m\n\u001b[32m     34\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m \u001b[33;03mstr: HTML content of the webpage in prettified format\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Initialize WebDriver\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m driver = \u001b[43mwebdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchrome_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Fetch the webpage\u001b[39;00m\n\u001b[32m     46\u001b[39m driver.get(url)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/selenium/webdriver/chrome/webdriver.py:45\u001b[39m, in \u001b[36mWebDriver.__init__\u001b[39m\u001b[34m(self, options, service, keep_alive)\u001b[39m\n\u001b[32m     42\u001b[39m service = service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[32m     43\u001b[39m options = options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbrowser_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCHROME\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrowserName\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvendor_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgoog\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mservice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/selenium/webdriver/chromium/webdriver.py:50\u001b[39m, in \u001b[36mChromiumDriver.__init__\u001b[39m\u001b[34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28mself\u001b[39m.service = service\n\u001b[32m     49\u001b[39m finder = DriverFinder(\u001b[38;5;28mself\u001b[39m.service, options)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfinder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_browser_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     51\u001b[39m     options.binary_location = finder.get_browser_path()\n\u001b[32m     52\u001b[39m     options.browser_version = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/selenium/webdriver/common/driver_finder.py:47\u001b[39m, in \u001b[36mDriverFinder.get_browser_path\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_browser_path\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_binary_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mbrowser_path\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/selenium/webdriver/common/driver_finder.py:78\u001b[39m, in \u001b[36mDriverFinder._binary_paths\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     77\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnable to obtain driver for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbrowser\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchDriverException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._paths\n",
      "\u001b[31mNoSuchDriverException\u001b[39m: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n"
     ]
    }
   ],
   "source": [
    "for symbol in tqdm(symbols):\n",
    "    display(Stock(symbol).get_key_financials())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download annual financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 14/43 [04:34<09:27, 19.58s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m stock = Stock(symbol)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     ticker_df = \u001b[43mStock\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_data_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ticker_df.isna().sum().sum() < \u001b[38;5;28mround\u001b[39m(\u001b[32m29\u001b[39m * minimum_feature_threshold):\n\u001b[32m     11\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m symbol \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m filtered_pd[\u001b[33m'\u001b[39m\u001b[33mTicker\u001b[39m\u001b[33m'\u001b[39m].tolist():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/stock_predictor/scripts/data_processer.py:30\u001b[39m, in \u001b[36mStock.get_data_key\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     28\u001b[39m     row_df[\u001b[33m\"\u001b[39m\u001b[33m3M Future Change\u001b[39m\u001b[33m\"\u001b[39m], row_df[\u001b[33m\"\u001b[39m\u001b[33m6M Future Change\u001b[39m\u001b[33m\"\u001b[39m], row_df[\u001b[33m\"\u001b[39m\u001b[33m9M Future Change\u001b[39m\u001b[33m\"\u001b[39m], row_df[\u001b[33m\"\u001b[39m\u001b[33m1Y Future Change\u001b[39m\u001b[33m\"\u001b[39m] = np.nan, np.nan, np.nan, np.nan\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     price_data = \u001b[43myf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrounding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     got_price = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     32\u001b[39m     day_offset = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/yfinance/utils.py:92\u001b[39m, in \u001b[36mlog_indent_decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/yfinance/multi.py:167\u001b[39m, in \u001b[36mdownload\u001b[39m\u001b[34m(tickers, start, end, actions, threads, ignore_tz, group_by, auto_adjust, back_adjust, repair, keepna, progress, period, interval, prepost, proxy, rounding, timeout, session, multi_level_index)\u001b[39m\n\u001b[32m    160\u001b[39m         _download_one_threaded(ticker, period=period, interval=interval,\n\u001b[32m    161\u001b[39m                                start=start, end=end, prepost=prepost,\n\u001b[32m    162\u001b[39m                                actions=actions, auto_adjust=auto_adjust,\n\u001b[32m    163\u001b[39m                                back_adjust=back_adjust, repair=repair, keepna=keepna,\n\u001b[32m    164\u001b[39m                                progress=(progress \u001b[38;5;129;01mand\u001b[39;00m i > \u001b[32m0\u001b[39m),\n\u001b[32m    165\u001b[39m                                rounding=rounding, timeout=timeout)\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shared._DFS) < \u001b[38;5;28mlen\u001b[39m(tickers):\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m         \u001b[43m_time\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m# download synchronously\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, ticker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tickers):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if build_new_dataset:\n",
    "    df = pd.DataFrame()\n",
    "    filtered_pd = pd.read_csv('../data/filtered_tickers.csv')\n",
    "    for symbol in tqdm(symbols, smoothing=0):\n",
    "        ticker_df = pd.DataFrame()\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        stock = Stock(symbol)\n",
    "        try:\n",
    "            ticker_df = Stock(symbol).get_data_key()\n",
    "            if ticker_df.isna().sum().sum() < round(29 * minimum_feature_threshold):\n",
    "                if symbol not in filtered_pd['Ticker'].tolist():\n",
    "                    filtered_pd = pd.concat([filtered_pd, pd.DataFrame([{'Ticker': symbol}])])\n",
    "                imputer = SimpleImputer()\n",
    "                for column in ticker_df.columns.drop(['Ticker', 'Name', 'Date', '3M Future Change', '6M Future Change', '9M Future Change', '1Y Future Change', 'Sector', 'Industry']):\n",
    "                    if not ticker_df[column].isna().all():\n",
    "                        ticker_df[column] = imputer.fit_transform(ticker_df[[column]])\n",
    "            else:\n",
    "                if symbol in filtered_pd['Ticker'].tolist():\n",
    "                    filtered_pd = filtered_pd[filtered_pd['Ticker'] != symbol]\n",
    "                    if debugging:\n",
    "                        print(f'Removed {symbol} from filtered tickers. Datapoints: {ticker_df.isna().sum().sum()}, Needed: {round(29 * minimum_feature_threshold)}')\n",
    "                continue\n",
    "            df = pd.concat([df, ticker_df], ignore_index=True)\n",
    "        except Exception as error:\n",
    "            if symbol in filtered_pd['Ticker'].tolist():\n",
    "                filtered_pd = filtered_pd[filtered_pd['Ticker'] != symbol]\n",
    "                if debugging:\n",
    "                    print(f'Removed {symbol} from filtered tickers because an exception was raised \\n {error}')\n",
    "            else:\n",
    "                if debugging:\n",
    "                    print(f\"{symbol}: exception raised: {error}\")\n",
    "            continue\n",
    "    filtered_pd.to_csv('../data/filtered_tickers.csv', index=False)\n",
    "    df.to_csv('../data/earnings_data.csv', index=False)\n",
    "else:\n",
    "    df = pd.read_csv('../data/earnings_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debugging:\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impution and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer()\n",
    "scaler = StandardScaler()\n",
    "for column in df.columns.drop(['Ticker', 'Name', 'Date', '3M Future Change', '6M Future Change', '9M Future Change', '1Y Future Change', 'Sector', 'Industry']):\n",
    "    df[column] = imputer.fit_transform(df[[column]])\n",
    "    scaler.fit(df[[column]])\n",
    "    df[column] = scaler.transform(df[[column]])\n",
    "\n",
    "le = LabelEncoder()\n",
    "for column in ['Sector', 'Industry']:\n",
    "    df[column] = df[column].astype(str)\n",
    "    le.fit(df[column])\n",
    "    df[column] = le.transform(df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "train_data = pd.DataFrame()\n",
    "for i in tqdm(range(int(len(df) / 4)), smoothing=0):\n",
    "    cont = False\n",
    "    for j in range(4):\n",
    "        if (df.loc[j+i*4, \"3M Future Change\"] > outlier or\n",
    "            df.loc[j+i*4, \"6M Future Change\"] > outlier or\n",
    "            df.loc[j+i*4, \"9M Future Change\"] > outlier or\n",
    "            df.loc[j+i*4, \"1Y Future Change\"] > outlier):\n",
    "            cont = True\n",
    "    if cont:\n",
    "        continue\n",
    "    pred_data = pd.concat([pred_data, df.iloc[[i*4]]]) \n",
    "    test_data = pd.concat([test_data, df.iloc[[1+i*4]]])\n",
    "    train_data = pd.concat([train_data, df.iloc[[2+i*4]]])\n",
    "    train_data = pd.concat([train_data, df.iloc[[3+i*4]]])\n",
    "if debugging:\n",
    "    print('Prediction Data:')\n",
    "    display(pred_data)\n",
    "    print(\"Test Data:\")\n",
    "    display(test_data)\n",
    "    print('Training Data:')\n",
    "    display(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Ticker', 'Name', 'Sector', 'Industry', 'Date', '3M Future Change', '6M Future Change', '9M Future Change', '1Y Future Change'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_columns \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSector\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndustry\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3M Future Change\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6M Future Change\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m9M Future Change\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1Y Future Change\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m label_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3M Future Change\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6M Future Change\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m9M Future Change\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1Y Future Change\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m X_pred \u001b[38;5;241m=\u001b[39m pred_data[training_columns]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:7098\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7097\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7098\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7099\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Ticker', 'Name', 'Sector', 'Industry', 'Date', '3M Future Change', '6M Future Change', '9M Future Change', '1Y Future Change'] not found in axis\""
     ]
    }
   ],
   "source": [
    "training_columns = train_data.columns.drop([\"Ticker\", \"Name\", \"Sector\", \"Industry\", \"Date\", '3M Future Change', '6M Future Change', '9M Future Change', '1Y Future Change'])\n",
    "label_columns = ['3M Future Change', '6M Future Change', '9M Future Change', '1Y Future Change']\n",
    "X_pred = pred_data[training_columns]\n",
    "X_test = test_data[training_columns]\n",
    "y_test = test_data[label_columns]\n",
    "X_train = train_data[training_columns]\n",
    "y_train = train_data[label_columns]\n",
    "if debugging:\n",
    "    print(\"X_pred:\")\n",
    "    display(X_pred)\n",
    "    print(\"X_test:\")\n",
    "    display(X_test)\n",
    "    print(\"y_test:\")\n",
    "    display(y_test)\n",
    "    print(\"X_train:\")\n",
    "    display(X_train)\n",
    "    print(\"y_train:\")\n",
    "    display(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_new_model:\n",
    "    opt = BayesSearchCV(\n",
    "        MLPWrapper(),\n",
    "        search_params,\n",
    "        n_iter=iterations,\n",
    "        random_state=42,\n",
    "        cv=cross_validations\n",
    "    )\n",
    "\n",
    "    opt.fit(X_train, y_train.values)\n",
    "    print(f\"Best parameters: {opt.best_params_}\")\n",
    "    model = opt.best_estimator_\n",
    "    \n",
    "    # model = MLPRegressor(\n",
    "    #     hidden_layer_sizes=hidden_layers,\n",
    "    #     learning_rate=\"adaptive\",\n",
    "    #     early_stopping=True,\n",
    "    #     verbose=True,\n",
    "    #     tol=0.00001,\n",
    "    #     n_iter_no_change=round(40000/hidden_layers[0]*4/len(hidden_layers))\n",
    "    # )\n",
    "    # print(f\"iter_no_change: {model.n_iter_no_change}\")\n",
    "    # model.fit(X_train, y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_new_model:\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    for i, target in enumerate(['3M Future Change', '6M Future Change', '9M Future Change', '1Y Future Change']):\n",
    "        y_test_actual = y_test[target]\n",
    "        y_test_pred_target = y_test_pred[:, i]\n",
    "\n",
    "        plt.figure(figsize=(11, 6))\n",
    "        plt.scatter(y_test_actual, y_test_pred_target, alpha=0.7, color='blue', label='Predictions')\n",
    "        plt.plot([y_test_actual.min(), y_test_actual.max()], [y_test_actual.min(), y_test_actual.max()], \n",
    "            color='red', linestyle='--', label='Perfect Fit')\n",
    "        plt.title(f'Predicted vs Actual Values ({target})')\n",
    "        plt.xlabel('Actual Values')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        mae = mean_absolute_error(y_test_actual, y_test_pred_target)\n",
    "        mse = mean_squared_error(y_test_actual, y_test_pred_target)\n",
    "        r2 = r2_score(y_test_actual, y_test_pred_target)\n",
    "\n",
    "        print(f'{target} - R²: {r2:.4f}')\n",
    "        print(f'{target} - MSE: {mse:.4f}')\n",
    "        print(f'{target} - MAE: {mae:.4f}')\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    mse = mean_squared_error(y_test, y_test_pred)\n",
    "    r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    print('\\nOverall Scores:')\n",
    "    print(f'Mean - R²: {r2:.4f}')\n",
    "    print(f'Mean - MSE: {mse:.4f}')\n",
    "    print(f'Mean - MAE: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_new_model:\n",
    "    test_results = pd.DataFrame({\n",
    "        'R²': r2,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'symbol_list': symbol_list,\n",
    "        \"iterations\": iterations,\n",
    "        'hidden_layer_sizes': [model.model.hidden_layer_sizes],\n",
    "        'max_iter': model.model.max_iter,\n",
    "        'n_iter_no_change': model.model.n_iter_no_change,\n",
    "        'learning_rate': model.model.learning_rate,\n",
    "        'learning_rate_init': model.model.learning_rate_init,\n",
    "        'batch_size': model.model.batch_size,\n",
    "        'tol': model.model.tol,\n",
    "        'alpha': model.model.alpha,\n",
    "        'shuffle': model.model.shuffle,\n",
    "    })\n",
    "    test_results.to_csv('../data/test_results.csv', mode='a', index=False)\n",
    "\n",
    "    # save model as new best if results are better than the current one\n",
    "    best_r2 = pd.read_csv('../models/best_model_results.csv').loc[0, 'R²']\n",
    "    if r2 > best_r2:\n",
    "        print(f'Old best R²: {best_r2}')\n",
    "        print(f'New best R²: {r2}')\n",
    "        print('Saving new best model...')\n",
    "        test_results.to_csv('../models/best_model_results.csv', mode='w', index=False)\n",
    "        with open('../models/best_model.pkl','wb') as f:\n",
    "            pickle.dump(model,f)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model R²: 0.0289336782535032\n"
     ]
    }
   ],
   "source": [
    "best_r2 = pd.read_csv('../models/best_model_results.csv').loc[0, 'R²']\n",
    "\n",
    "with open('../models/best_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    print(f'Best model R²: {best_r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Asset Turnover\n- Book Value Per Share\n- Current Ratio\n- Days Sales In Receivables\n- Debt\\/Equity Ratio\n- ...\nFeature names seen at fit time, yet now missing:\n- Accounts Payable\n- Accounts Receivable\n- Accrued Interest Receivable\n- Accumulated Depreciation\n- Additional Paid In Capital\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_pred)):\n\u001b[0;32m----> 5\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_pred\u001b[38;5;241m.\u001b[39miloc[[i]])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m     y_pred_3m, y_pred_6m, y_pred_9m, y_pred_1y \u001b[38;5;241m=\u001b[39m y_pred\n\u001b[1;32m      7\u001b[0m     avg \u001b[38;5;241m=\u001b[39m (y_pred_3m \u001b[38;5;241m+\u001b[39m y_pred_6m \u001b[38;5;241m+\u001b[39m y_pred_9m \u001b[38;5;241m+\u001b[39m y_pred_1y) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1744\u001b[0m, in \u001b[0;36mMLPRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the multi-layer perceptron model.\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \n\u001b[1;32m   1733\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;124;03m    The predicted values.\u001b[39;00m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1744\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1748\u001b[0m, in \u001b[0;36mMLPRegressor._predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Private predict method with optional input validation\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1748\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pass_fast(X, check_input\u001b[38;5;241m=\u001b[39mcheck_input)\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1750\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:204\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the trained model\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03mThis is the same as _forward_pass but does not record the activations\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    The decision function of the samples for each class in the model.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[0;32m--> 204\u001b[0m     X \u001b[38;5;241m=\u001b[39m validate_data(\u001b[38;5;28mself\u001b[39m, X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m], reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# Initialize first layer\u001b[39;00m\n\u001b[1;32m    207\u001b[0m activation \u001b[38;5;241m=\u001b[39m X\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2929\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[1;32m   2846\u001b[0m     _estimator,\n\u001b[1;32m   2847\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2853\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m   2854\u001b[0m ):\n\u001b[1;32m   2855\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[1;32m   2856\u001b[0m \n\u001b[1;32m   2857\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2927\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m   2928\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2929\u001b[0m     _check_feature_names(_estimator, X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[1;32m   2930\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[1;32m   2931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2787\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m   2785\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2787\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Asset Turnover\n- Book Value Per Share\n- Current Ratio\n- Days Sales In Receivables\n- Debt\\/Equity Ratio\n- ...\nFeature names seen at fit time, yet now missing:\n- Accounts Payable\n- Accounts Receivable\n- Accrued Interest Receivable\n- Accumulated Depreciation\n- Additional Paid In Capital\n- ...\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv('../data/earnings_data.csv')\n",
    "\n",
    "results = []\n",
    "for i in range(len(X_pred)):\n",
    "    y_pred = model.predict(X_pred.iloc[[i]])[0]\n",
    "    y_pred_3m, y_pred_6m, y_pred_9m, y_pred_1y = y_pred\n",
    "    avg = (y_pred_3m + y_pred_6m + y_pred_9m + y_pred_1y) / 4\n",
    "    results.append({\n",
    "        'Ticker': df_raw.loc[i*4, 'Ticker'],\n",
    "        'Name': df_raw.loc[i*4, 'Name'],\n",
    "        'mean (%)': avg * 100,\n",
    "        '3m (%)': y_pred_3m * 100,\n",
    "        '6m (%)': y_pred_6m * 100,\n",
    "        '9m (%)': y_pred_9m * 100,\n",
    "        '1y (%)': y_pred_1y * 100\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ticker(ticker_str):\n",
    "    try:\n",
    "        ticker_str = str(ticker_str).upper()\n",
    "        ticker_str = ticker_str.replace(\"'\", \"\")\n",
    "        ticker_str = ticker_str.replace('\"', \"\")\n",
    "        row = results_df[results_df['Ticker'] == ticker_str]\n",
    "        if row.empty:\n",
    "            return (f\"Not enough data for this stock at this moment \\n Try another\", \"\", \"\", \"\", \"\")\n",
    "        row = row.iloc[0]\n",
    "        return (\n",
    "            f\"{row['3m (%)']:.2f}\",\n",
    "            f\"{row['6m (%)']:.2f}\",\n",
    "            f\"{row['9m (%)']:.2f}\",\n",
    "            f\"{row['1y (%)']:.2f}\",\n",
    "            f\"{row['mean (%)']:.2f}\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return (f\"Error: {e}\", \"\", \"\", \"\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://d6f7567b4876962a6e.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d6f7567b4876962a6e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iface = gr.Interface(\n",
    "    fn=predict_ticker,\n",
    "    inputs=gr.Textbox(label=\"Ticker e.g. 'TSLA' or 'NVDA'\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"3 Month Change Prediction (%)\"),\n",
    "        gr.Textbox(label=\"6 Month Change Prediction (%)\"),\n",
    "        gr.Textbox(label=\"9 Month Change Prediction (%)\"),\n",
    "        gr.Textbox(label=\"1 Year Change Prediction (%)\"),\n",
    "        gr.Textbox(label=\"Mean Change Prediction (%)\"),\n",
    "    ],\n",
    "    title=\"Stock Price Prediction Model\",\n",
    "    description=\" \"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
