{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e85762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import methods.selenium_patch as selenium_patch\n",
    "from tqdm import tqdm\n",
    "from methods.scraper import *\n",
    "from methods.model_methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9d4abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = pd.read_csv(\"../data/tickers/simple_tickers.csv\")[\"Ticker\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d069214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [10:11<00:00,  7.37s/it]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for ticker in tqdm(tickers, smoothing=0):\n",
    "    try:\n",
    "        data.append(get_data(ticker, frequency=\"quarterly\"))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7be20205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvictor-vangkilde\u001b[0m (\u001b[33mvictor-vangkilde-university-of-copenhagen\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/victorvj/Documents/stock_predictor/src/wandb/run-20260213_110258-qa7yfyg5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/victor-vangkilde-university-of-copenhagen/Stock%20Price%20Predictor/runs/qa7yfyg5' target=\"_blank\">lstm-run-1770976977</a></strong> to <a href='https://wandb.ai/victor-vangkilde-university-of-copenhagen/Stock%20Price%20Predictor' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/victor-vangkilde-university-of-copenhagen/Stock%20Price%20Predictor' target=\"_blank\">https://wandb.ai/victor-vangkilde-university-of-copenhagen/Stock%20Price%20Predictor</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/victor-vangkilde-university-of-copenhagen/Stock%20Price%20Predictor/runs/qa7yfyg5' target=\"_blank\">https://wandb.ai/victor-vangkilde-university-of-copenhagen/Stock%20Price%20Predictor/runs/qa7yfyg5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb tracking enabled: project=Stock Price Predictor, run=lstm-run-1770976977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73it [10:09,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0: done (best loss=0.019361, best R2=0.0419, pred=-7.1289).\n",
      "Dataset 1: done (best loss=0.016635, best R2=-0.0129, pred=0.7651).\n",
      "Dataset 2: done (best loss=0.020135, best R2=0.0674, pred=7.1752).\n",
      "Dataset 3: done (best loss=0.029357, best R2=-0.0178, pred=15.9843).\n",
      "Dataset 4: done (best loss=0.145250, best R2=-0.0135, pred=7.4421).\n",
      "Dataset 5: done (best loss=0.415643, best R2=-0.2622, pred=-4.3195).\n",
      "Dataset 6: done (best loss=0.057379, best R2=-4.8958, pred=-20.5093).\n",
      "Dataset 7: done (best loss=0.095895, best R2=0.0037, pred=10.2186).\n",
      "Dataset 8: done (best loss=0.140859, best R2=-0.0268, pred=9.4024).\n",
      "Dataset 9: done (best loss=0.044117, best R2=-3.5699, pred=0.6647).\n",
      "Dataset 10: done (best loss=1.012897, best R2=-1.9955, pred=-13.4894).\n",
      "Dataset 11: done (best loss=0.016038, best R2=-0.0967, pred=3.0056).\n",
      "Dataset 12: done (best loss=0.125790, best R2=-0.0189, pred=7.1701).\n",
      "Dataset 13: done (best loss=0.309757, best R2=-45.7277, pred=12.0267).\n",
      "Dataset 14: done (best loss=0.092389, best R2=0.0024, pred=7.6397).\n",
      "Dataset 15: done (best loss=0.172144, best R2=-0.8223, pred=-0.0580).\n",
      "Dataset 16: done (best loss=0.537422, best R2=-16.4461, pred=-6.6475).\n",
      "Dataset 17: done (best loss=0.377436, best R2=-6.1609, pred=-5.5838).\n",
      "Dataset 18: done (best loss=0.097265, best R2=-0.0602, pred=-2.8952).\n",
      "Dataset 19: done (best loss=0.052641, best R2=-0.0620, pred=3.8185).\n",
      "Dataset 20: done (best loss=0.018501, best R2=-0.1604, pred=-12.7615).\n",
      "Dataset 21: done (best loss=0.192888, best R2=-0.4248, pred=3.7180).\n",
      "Dataset 22: done (best loss=0.064973, best R2=-1.8285, pred=-10.6579).\n",
      "Dataset 23: done (best loss=0.009150, best R2=-509.8485, pred=-10.7844).\n",
      "Dataset 24: done (best loss=0.013312, best R2=-0.1000, pred=11.0033).\n",
      "Dataset 25: done (best loss=0.031763, best R2=-0.0238, pred=-8.5488).\n",
      "Dataset 26: done (best loss=0.144813, best R2=-0.0014, pred=-21.6379).\n",
      "Dataset 27: done (best loss=0.160547, best R2=-0.0038, pred=7.2067).\n",
      "Dataset 28: done (best loss=0.039016, best R2=-0.3541, pred=1.3330).\n",
      "Dataset 29: done (best loss=0.133414, best R2=-0.0986, pred=14.5383).\n",
      "Dataset 30: done (best loss=0.087373, best R2=0.0017, pred=4.6589).\n",
      "Dataset 31: done (best loss=0.026761, best R2=0.0752, pred=0.5059).\n",
      "Dataset 32: done (best loss=0.281958, best R2=-0.1266, pred=-3.7978).\n",
      "Dataset 33: done (best loss=0.481830, best R2=-2.8960, pred=-4.8140).\n",
      "Dataset 34: done (best loss=0.017121, best R2=0.0033, pred=2.9901).\n",
      "Dataset 35: skipped (missing required columns).\n",
      "Dataset 36: done (best loss=0.296627, best R2=-0.0091, pred=2.7914).\n",
      "Dataset 37: done (best loss=0.100534, best R2=0.0189, pred=6.7659).\n",
      "Dataset 38: done (best loss=0.223802, best R2=-0.0050, pred=-2.9291).\n",
      "Dataset 39: done (best loss=0.776682, best R2=-16.2415, pred=-26.3360).\n",
      "Dataset 40: done (best loss=0.036089, best R2=-9.1218, pred=-0.2569).\n",
      "Dataset 41: done (best loss=0.042825, best R2=-0.8719, pred=5.1974).\n",
      "Dataset 42: done (best loss=0.010013, best R2=-0.0088, pred=7.8227).\n",
      "Dataset 43: done (best loss=0.521481, best R2=-0.6837, pred=0.9495).\n",
      "Dataset 44: done (best loss=0.042259, best R2=-0.7621, pred=6.8486).\n",
      "Dataset 45: done (best loss=0.680893, best R2=-2.5811, pred=0.7403).\n",
      "Dataset 46: done (best loss=0.577175, best R2=-0.6531, pred=8.4820).\n",
      "Dataset 47: done (best loss=0.340618, best R2=-3.3559, pred=-1.9081).\n",
      "Dataset 48: done (best loss=0.042471, best R2=-0.0065, pred=7.8261).\n",
      "Dataset 49: done (best loss=0.072730, best R2=-0.1094, pred=11.4411).\n",
      "Dataset 50: done (best loss=0.048155, best R2=-6.1088, pred=4.3030).\n",
      "Dataset 51: skipped (missing required columns).\n",
      "Dataset 52: done (best loss=0.075574, best R2=0.0232, pred=0.1595).\n",
      "Dataset 53: done (best loss=0.083428, best R2=-0.2302, pred=9.7482).\n",
      "Dataset 54: done (best loss=0.013069, best R2=-0.0112, pred=-6.8461).\n",
      "Dataset 55: done (best loss=1.468893, best R2=-1.3491, pred=4.0022).\n",
      "Dataset 56: done (best loss=0.099948, best R2=0.0094, pred=-10.8780).\n",
      "Dataset 57: done (best loss=0.060237, best R2=-2.8336, pred=-6.7966).\n",
      "Dataset 58: done (best loss=0.031344, best R2=0.0310, pred=-14.5004).\n",
      "Dataset 59: done (best loss=0.137859, best R2=-0.7509, pred=-3.3566).\n",
      "Dataset 60: done (best loss=0.002096, best R2=0.2339, pred=-6.6820).\n",
      "Dataset 61: done (best loss=0.160770, best R2=-0.1409, pred=-14.3721).\n",
      "Dataset 62: done (best loss=0.005113, best R2=0.0018, pred=-5.5289).\n",
      "Dataset 63: done (best loss=0.182817, best R2=-5.8780, pred=-29.3664).\n",
      "Dataset 64: done (best loss=0.645603, best R2=-1.1361, pred=1.8263).\n",
      "Dataset 65: done (best loss=0.002093, best R2=0.0322, pred=-7.7667).\n",
      "Dataset 66: done (best loss=0.089671, best R2=0.0013, pred=8.9620).\n",
      "Dataset 67: skipped (missing required columns).\n",
      "Dataset 68: done (best loss=0.159252, best R2=-2.6081, pred=-17.4101).\n",
      "Dataset 69: done (best loss=0.009272, best R2=-1.0924, pred=0.3390).\n",
      "Dataset 70: done (best loss=0.081335, best R2=-0.0586, pred=8.8775).\n",
      "Dataset 71: done (best loss=0.002356, best R2=-0.2511, pred=12.1262).\n",
      "Dataset 72: done (best loss=0.101255, best R2=-0.0905, pred=4.1717).\n",
      "\n",
      "===== Aggregate Metrics =====\n",
      "Models trained: 70 / 73\n",
      "Average best validation loss: 0.181517\n",
      "Average best validation R^2: -9.3208\n",
      "\n",
      "===== Predictions for First Row (per dataset) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dataset_idx",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prediction_first_row",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "best_val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "best_val_r2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "best_window_size",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5119e233-a1a7-470f-ba00-14c06d5afd30",
       "rows": [
        [
         "0",
         "0",
         "MATAS.CO",
         "-7.128918647766113",
         "0.019361352548003197",
         "0.04186201095581055",
         "3"
        ],
        [
         "1",
         "1",
         "TRIFOR.CO",
         "0.7651030421257019",
         "0.016634950414299965",
         "-0.012902259826660156",
         "12"
        ],
        [
         "2",
         "2",
         "RHM.DE",
         "7.1751580238342285",
         "0.020134545862674713",
         "0.06735658645629883",
         "8"
        ],
        [
         "3",
         "3",
         "SAAB-B.ST",
         "15.98427963256836",
         "0.02935723587870598",
         "-0.017802000045776367",
         "8"
        ],
        [
         "4",
         "4",
         "KOG.OL",
         "7.442135334014893",
         "0.14525002241134644",
         "-0.01350092887878418",
         "13"
        ],
        [
         "5",
         "5",
         "GMAB.CO",
         "-4.319538593292236",
         "0.41564300656318665",
         "-0.2622450590133667",
         "15"
        ],
        [
         "6",
         "6",
         "GN.CO",
         "-20.509279251098633",
         "0.057379450649023056",
         "-4.895776271820068",
         "11"
        ],
        [
         "7",
         "7",
         "NVDA",
         "10.218575477600098",
         "0.09589467197656631",
         "0.0037009716033935547",
         "7"
        ],
        [
         "8",
         "8",
         "LLY",
         "9.402369499206543",
         "0.14085891842842102",
         "-0.026825308799743652",
         "9"
        ],
        [
         "9",
         "9",
         "DANSKE.CO",
         "0.6647381782531738",
         "0.04411662369966507",
         "-3.5699405670166016",
         "7"
        ],
        [
         "10",
         "10",
         "CARL-B.CO",
         "-13.489434242248535",
         "1.012897253036499",
         "-1.995537519454956",
         "5"
        ],
        [
         "11",
         "11",
         "MAERSK-B.CO",
         "3.0055649280548096",
         "0.016037778928875923",
         "-0.09669077396392822",
         "16"
        ],
        [
         "12",
         "12",
         "RBREW.CO",
         "7.170137882232666",
         "0.12578988075256348",
         "-0.01886451244354248",
         "13"
        ],
        [
         "13",
         "13",
         "ISS.CO",
         "12.026676177978516",
         "0.3097572922706604",
         "-45.72768020629883",
         "8"
        ],
        [
         "14",
         "14",
         "DSV.CO",
         "7.639666557312012",
         "0.09238926321268082",
         "0.0024419426918029785",
         "7"
        ],
        [
         "15",
         "15",
         "SCHO.CO",
         "-0.05797017738223076",
         "0.1721440553665161",
         "-0.8222925662994385",
         "12"
        ],
        [
         "16",
         "16",
         "JYSK.CO",
         "-6.6475443840026855",
         "0.5374217629432678",
         "-16.446075439453125",
         "11"
        ],
        [
         "17",
         "17",
         "TER",
         "-5.583829402923584",
         "0.3774361312389374",
         "-6.160895824432373",
         "11"
        ],
        [
         "18",
         "18",
         "NFLX",
         "-2.895230293273926",
         "0.09726549685001373",
         "-0.06024670600891113",
         "16"
        ],
        [
         "19",
         "19",
         "STG.CO",
         "3.8185479640960693",
         "0.05264127254486084",
         "-0.06204259395599365",
         "15"
        ],
        [
         "20",
         "20",
         "NOVO-B.CO",
         "-12.761541366577148",
         "0.01850097067654133",
         "-0.16040146350860596",
         "12"
        ],
        [
         "21",
         "21",
         "NKT.CO",
         "3.7179694175720215",
         "0.19288767874240875",
         "-0.4248110055923462",
         "11"
        ],
        [
         "22",
         "22",
         "TSLA",
         "-10.657866477966309",
         "0.0649731457233429",
         "-1.8285250663757324",
         "13"
        ],
        [
         "23",
         "23",
         "DEMANT.CO",
         "-10.784420013427734",
         "0.009150465950369835",
         "-509.8485412597656",
         "1"
        ],
        [
         "24",
         "24",
         "ALSYDB.CO",
         "11.003320693969727",
         "0.013312269002199173",
         "-0.09996819496154785",
         "15"
        ],
        [
         "25",
         "25",
         "COLO-B.CO",
         "-8.548815727233887",
         "0.031762782484292984",
         "-0.02379429340362549",
         "7"
        ],
        [
         "26",
         "26",
         "CBRAIN.CO",
         "-21.637868881225586",
         "0.1448133885860443",
         "-0.0013506412506103516",
         "8"
        ],
        [
         "27",
         "27",
         "NETC.CO",
         "7.206728458404541",
         "0.1605473756790161",
         "-0.0037763118743896484",
         "12"
        ],
        [
         "28",
         "28",
         "TRMD",
         "1.3330345153808594",
         "0.03901609778404236",
         "-0.3540527820587158",
         "10"
        ],
        [
         "29",
         "29",
         "CBK.DE",
         "14.538254737854004",
         "0.1334141492843628",
         "-0.0985562801361084",
         "16"
        ],
        [
         "30",
         "30",
         "AAPL",
         "4.658901691436768",
         "0.08737340569496155",
         "0.0016571879386901855",
         "7"
        ],
        [
         "31",
         "31",
         "AMZN",
         "0.5059248208999634",
         "0.026761353015899658",
         "0.07523053884506226",
         "6"
        ],
        [
         "32",
         "32",
         "MSFT",
         "-3.7978358268737793",
         "0.28195756673812866",
         "-0.12663328647613525",
         "11"
        ],
        [
         "33",
         "33",
         "GOOGL",
         "-4.814001560211182",
         "0.4818296730518341",
         "-2.8960182666778564",
         "11"
        ],
        [
         "34",
         "34",
         "META",
         "2.990084171295166",
         "0.017120644450187683",
         "0.00329667329788208",
         "3"
        ],
        [
         "35",
         "36",
         "HIMS",
         "2.7913529872894287",
         "0.2966265082359314",
         "-0.00911402702331543",
         "1"
        ],
        [
         "36",
         "37",
         "SPG.CO",
         "6.765918254852295",
         "0.1005336195230484",
         "0.018887460231781006",
         "7"
        ],
        [
         "37",
         "38",
         "SOLAR-B.CO",
         "-2.929143190383911",
         "0.22380223870277405",
         "-0.0049828290939331055",
         "7"
        ],
        [
         "38",
         "39",
         "FLUG-B.CO",
         "-26.336042404174805",
         "0.7766818404197693",
         "-16.241540908813477",
         "6"
        ],
        [
         "39",
         "40",
         "DNORD.CO",
         "-0.2568901777267456",
         "0.0360892079770565",
         "-9.121831893920898",
         "5"
        ],
        [
         "40",
         "41",
         "NDA-DK.CO",
         "5.197415351867676",
         "0.04282544180750847",
         "-0.8718520402908325",
         "16"
        ],
        [
         "41",
         "42",
         "RILBA.CO",
         "7.8226847648620605",
         "0.010012784041464329",
         "-0.008756875991821289",
         "12"
        ],
        [
         "42",
         "43",
         "HVID.CO",
         "0.9494608640670776",
         "0.5214807391166687",
         "-0.6837388277053833",
         "12"
        ],
        [
         "43",
         "44",
         "SKJE.CO",
         "6.848576545715332",
         "0.04225901886820793",
         "-0.7620530128479004",
         "15"
        ],
        [
         "44",
         "45",
         "LASP.CO",
         "0.7403210401535034",
         "0.680892825126648",
         "-2.581057548522949",
         "10"
        ],
        [
         "45",
         "46",
         "FOBANK.CO",
         "8.481998443603516",
         "0.577175498008728",
         "-0.6530513763427734",
         "15"
        ],
        [
         "46",
         "47",
         "LOLB.CO",
         "-1.908101201057434",
         "0.34061822295188904",
         "-3.3558826446533203",
         "11"
        ],
        [
         "47",
         "48",
         "DAB.CO",
         "7.826141357421875",
         "0.04247063398361206",
         "-0.006466865539550781",
         "10"
        ],
        [
         "48",
         "49",
         "DJUR.CO",
         "11.4411039352417",
         "0.07273025065660477",
         "-0.10943293571472168",
         "15"
        ],
        [
         "49",
         "50",
         "MNBA.CO",
         "4.303036689758301",
         "0.04815497621893883",
         "-6.108829975128174",
         "12"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 70
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_idx</th>\n",
       "      <th>ticker</th>\n",
       "      <th>prediction_first_row</th>\n",
       "      <th>best_val_loss</th>\n",
       "      <th>best_val_r2</th>\n",
       "      <th>best_window_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MATAS.CO</td>\n",
       "      <td>-7.128919</td>\n",
       "      <td>0.019361</td>\n",
       "      <td>0.041862</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TRIFOR.CO</td>\n",
       "      <td>0.765103</td>\n",
       "      <td>0.016635</td>\n",
       "      <td>-0.012902</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RHM.DE</td>\n",
       "      <td>7.175158</td>\n",
       "      <td>0.020135</td>\n",
       "      <td>0.067357</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SAAB-B.ST</td>\n",
       "      <td>15.984280</td>\n",
       "      <td>0.029357</td>\n",
       "      <td>-0.017802</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>KOG.OL</td>\n",
       "      <td>7.442135</td>\n",
       "      <td>0.145250</td>\n",
       "      <td>-0.013501</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>68</td>\n",
       "      <td>MTHH.CO</td>\n",
       "      <td>-17.410130</td>\n",
       "      <td>0.159252</td>\n",
       "      <td>-2.608117</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>69</td>\n",
       "      <td>AOJ-B.CO</td>\n",
       "      <td>0.338953</td>\n",
       "      <td>0.009272</td>\n",
       "      <td>-1.092447</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>70</td>\n",
       "      <td>LMT</td>\n",
       "      <td>8.877452</td>\n",
       "      <td>0.081335</td>\n",
       "      <td>-0.058603</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>71</td>\n",
       "      <td>RTX</td>\n",
       "      <td>12.126162</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>-0.251122</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>72</td>\n",
       "      <td>RBLN-B.CO</td>\n",
       "      <td>4.171732</td>\n",
       "      <td>0.101255</td>\n",
       "      <td>-0.090492</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset_idx     ticker  prediction_first_row  best_val_loss  best_val_r2  \\\n",
       "0             0   MATAS.CO             -7.128919       0.019361     0.041862   \n",
       "1             1  TRIFOR.CO              0.765103       0.016635    -0.012902   \n",
       "2             2     RHM.DE              7.175158       0.020135     0.067357   \n",
       "3             3  SAAB-B.ST             15.984280       0.029357    -0.017802   \n",
       "4             4     KOG.OL              7.442135       0.145250    -0.013501   \n",
       "..          ...        ...                   ...            ...          ...   \n",
       "65           68    MTHH.CO            -17.410130       0.159252    -2.608117   \n",
       "66           69   AOJ-B.CO              0.338953       0.009272    -1.092447   \n",
       "67           70        LMT              8.877452       0.081335    -0.058603   \n",
       "68           71        RTX             12.126162       0.002356    -0.251122   \n",
       "69           72  RBLN-B.CO              4.171732       0.101255    -0.090492   \n",
       "\n",
       "    best_window_size  \n",
       "0                  3  \n",
       "1                 12  \n",
       "2                  8  \n",
       "3                  8  \n",
       "4                 13  \n",
       "..               ...  \n",
       "65                14  \n",
       "66                13  \n",
       "67                11  \n",
       "68                15  \n",
       "69                14  \n",
       "\n",
       "[70 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total runtime: 611.82 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>aggregate_avg_best_val_loss</td><td>▁</td></tr><tr><td>aggregate_avg_best_val_r2</td><td>▁</td></tr><tr><td>aggregate_models_trained</td><td>▁</td></tr><tr><td>aggregate_total_datasets</td><td>▁</td></tr><tr><td>dataset_best_val_loss</td><td>▁▂▁▁▂▁▂▂▂▄▁▂▁▁▁▂▁▂▁▂▁▁▅▁▁▃▁▄▃▁▁█▁▁▂▂▁▁▁▁</td></tr><tr><td>dataset_best_val_r2</td><td>████▇████▁█▅██████████████▇█▇███████████</td></tr><tr><td>dataset_best_window_size</td><td>▆▄▄▆▇▃▄▃▂▄▅▅▇▆▅▃▆█▃▅▁▃▃▂█▆▇▅▅▇▇▅▇▄▆▇▁▆▅▇</td></tr><tr><td>dataset_idx</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇██</td></tr><tr><td>dataset_prediction_first_row</td><td>▅▆█▄▁▅▃▇▆▅▄▄▃▆▃▁▅█▆▄▆▆▄▅▆▇▆▇▅▄▄▂▄▄▄▅▄▂▅▆</td></tr><tr><td>runtime_seconds</td><td>▁</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>aggregate_avg_best_val_loss</td><td>0.18152</td></tr><tr><td>aggregate_avg_best_val_r2</td><td>-9.32083</td></tr><tr><td>aggregate_models_trained</td><td>70</td></tr><tr><td>aggregate_total_datasets</td><td>73</td></tr><tr><td>dataset_best_val_loss</td><td>0.10125</td></tr><tr><td>dataset_best_val_r2</td><td>-0.09049</td></tr><tr><td>dataset_best_window_size</td><td>14</td></tr><tr><td>dataset_idx</td><td>72</td></tr><tr><td>dataset_prediction_first_row</td><td>4.17173</td></tr><tr><td>runtime_seconds</td><td>611.82175</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lstm-run-1770976977</strong> at: <a href='https://wandb.ai/victor-vangkilde-university-of-copenhagen/Stock%20Price%20Predictor/runs/qa7yfyg5' target=\"_blank\">https://wandb.ai/victor-vangkilde-university-of-copenhagen/Stock%20Price%20Predictor/runs/qa7yfyg5</a><br> View project at: <a href='https://wandb.ai/victor-vangkilde-university-of-copenhagen/Stock%20Price%20Predictor' target=\"_blank\">https://wandb.ai/victor-vangkilde-university-of-copenhagen/Stock%20Price%20Predictor</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260213_110258-qa7yfyg5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "\n",
    "# Optional experiment tracking\n",
    "try:\n",
    "    import wandb\n",
    "except ImportError:\n",
    "    wandb = None\n",
    "\n",
    "# Train one model per dataframe in `data`, then aggregate metrics + predictions.\n",
    "\n",
    "target_col = \"Future Change%\"\n",
    "drop_cols = [\"Ticker\", \"Close Price\", \"Future Change%\"]\n",
    "\n",
    "# Hyperparameters\n",
    "HIDDEN_SIZE = 30\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "EPOCHS = 25\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 1e-4\n",
    "WINDOW_SIZE = 7\n",
    "\n",
    "# Weights & Biases settings\n",
    "USE_WANDB = True\n",
    "WANDB_PROJECT = \"Stock Price Predictor\"\n",
    "WANDB_ENTITY = \"victor-vangkilde-university-of-copenhagen\"\n",
    "WANDB_RUN_NAME = f\"lstm-run-{int(time.time())}\"\n",
    "\n",
    "\n",
    "class StockLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob):\n",
    "        super(StockLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout_prob if num_layers > 1 else 0.0,\n",
    "        )\n",
    "        self.fc_1 = nn.Linear(hidden_size, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_2 = nn.Linear(16, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]  # last time step\n",
    "        out = self.fc_1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc_2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def create_sliding_dataset(X_scaled, y_scaled, indices, seq_len):\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for i in indices:\n",
    "        if i + seq_len <= len(X_scaled):\n",
    "            window = X_scaled[i : i + seq_len]\n",
    "            window = window[::-1]  # old -> new\n",
    "            xs.append(window)\n",
    "            ys.append(y_scaled[i])\n",
    "\n",
    "    if not xs:\n",
    "        return None, None\n",
    "\n",
    "    return (\n",
    "        torch.tensor(np.array(xs), dtype=torch.float32),\n",
    "        torch.tensor(np.array(ys), dtype=torch.float32),\n",
    "    )\n",
    "\n",
    "\n",
    "def train_single_dataframe(df, dataset_idx, wandb_run=None):\n",
    "    # Basic checks\n",
    "    if df is None or not isinstance(df, pd.DataFrame) or df.empty:\n",
    "        return None, f\"Dataset {dataset_idx}: skipped (empty or invalid dataframe).\"\n",
    "\n",
    "    required = {\"Future Change%\"}\n",
    "    if not required.issubset(set(df.columns)):\n",
    "        return None, f\"Dataset {dataset_idx}: skipped (missing required columns).\"\n",
    "\n",
    "    local_drop_cols = [c for c in drop_cols if c in df.columns]\n",
    "    feature_df = df.drop(local_drop_cols, axis=1)\n",
    "\n",
    "    if feature_df.shape[1] == 0:\n",
    "        return None, f\"Dataset {dataset_idx}: skipped (no usable features after dropping columns).\"\n",
    "\n",
    "    n_rows = len(df)\n",
    "    if n_rows < 8:\n",
    "        return None, f\"Dataset {dataset_idx}: skipped (not enough rows: {n_rows}).\"\n",
    "\n",
    "    # Time-based split: 0 is prediction row (newest)\n",
    "    idx_pred = [0]\n",
    "    n_val = max(2, int(0.2 * n_rows))\n",
    "    n_val = min(n_val, n_rows - 3)  # keep enough train rows\n",
    "\n",
    "    if n_val < 2:\n",
    "        return None, f\"Dataset {dataset_idx}: skipped (not enough rows for validation).\"\n",
    "\n",
    "    idx_val = list(range(1, 1 + n_val))\n",
    "    idx_train = list(range(1 + n_val, n_rows))\n",
    "\n",
    "    if len(idx_train) < 2:\n",
    "        return None, f\"Dataset {dataset_idx}: skipped (not enough training rows).\"\n",
    "\n",
    "    X = feature_df.values\n",
    "    y = df[[target_col]].values\n",
    "\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "\n",
    "    X_train_raw = X[idx_train]\n",
    "    y_train_raw = y[idx_train]\n",
    "\n",
    "    scaler_X.fit(X_train_raw)\n",
    "    scaler_y.fit(y_train_raw)\n",
    "\n",
    "    X_scaled = scaler_X.transform(X)\n",
    "    y_scaled = scaler_y.transform(y)\n",
    "\n",
    "    window_sizes = [WINDOW_SIZE]\n",
    "    best_window_loss = float(\"inf\")\n",
    "    best_window_r2 = -float(\"inf\")\n",
    "    best_window_size = -1\n",
    "    best_model_wts = None\n",
    "\n",
    "    ticker_value = df.iloc[0][\"Ticker\"] if \"Ticker\" in df.columns else f\"dataset_{dataset_idx}\"\n",
    "\n",
    "    for w_size in window_sizes:\n",
    "        X_train_t, y_train_t = create_sliding_dataset(X_scaled, y_scaled, idx_train, w_size)\n",
    "        X_val_t, y_val_t = create_sliding_dataset(X_scaled, y_scaled, idx_val, w_size)\n",
    "\n",
    "        if X_train_t is None or X_val_t is None or y_train_t is None or y_val_t is None or len(X_val_t) < 2:\n",
    "            continue\n",
    "\n",
    "        input_features = X_train_t.shape[2]\n",
    "        torch.manual_seed(42)\n",
    "        model = StockLSTM(\n",
    "            input_features,\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            num_layers=NUM_LAYERS,\n",
    "            output_size=1,\n",
    "            dropout_prob=DROPOUT,\n",
    "        )\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", patience=500, factor=0.5)\n",
    "\n",
    "        best_val_loss_local = float(\"inf\")\n",
    "        best_val_r2_local = -float(\"inf\")\n",
    "        best_wts_local = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        for _ in range(EPOCHS):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            train_out = model(X_train_t)\n",
    "            train_loss = criterion(train_out, y_train_t)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_out = model(X_val_t)\n",
    "                val_loss = criterion(val_out, y_val_t).item()\n",
    "\n",
    "                y_true = y_val_t.detach().cpu().numpy().reshape(-1)\n",
    "                y_pred = val_out.detach().cpu().numpy().reshape(-1)\n",
    "                val_r2 = r2_score(y_true, y_pred) if len(y_true) >= 2 else np.nan\n",
    "\n",
    "                if val_loss < best_val_loss_local:\n",
    "                    best_val_loss_local = val_loss\n",
    "                    best_val_r2_local = val_r2\n",
    "                    best_wts_local = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        if wandb_run is not None:\n",
    "            wandb_run.log(\n",
    "                {\n",
    "                    \"dataset_idx\": dataset_idx,\n",
    "                    \"ticker\": str(ticker_value),\n",
    "                    \"window_size\": w_size,\n",
    "                    \"window_best_val_loss\": float(best_val_loss_local),\n",
    "                    \"window_best_val_r2\": float(best_val_r2_local) if not np.isnan(best_val_r2_local) else np.nan,\n",
    "                    \"window_last_train_loss\": float(train_loss.item()),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if best_val_loss_local < best_window_loss:\n",
    "            best_window_loss = best_val_loss_local\n",
    "            best_window_r2 = best_val_r2_local\n",
    "            best_window_size = w_size\n",
    "            best_model_wts = best_wts_local\n",
    "\n",
    "    if best_model_wts is None:\n",
    "        return None, f\"Dataset {dataset_idx}: skipped (no valid window size found).\"\n",
    "\n",
    "    # Predict first row (index 0) with best model/window\n",
    "    X_pred_t, _ = create_sliding_dataset(X_scaled, y_scaled, idx_pred, best_window_size)\n",
    "    if X_pred_t is None:\n",
    "        return None, f\"Dataset {dataset_idx}: skipped (could not build prediction window).\"\n",
    "\n",
    "    input_features = X_pred_t.shape[2]\n",
    "    model = StockLSTM(\n",
    "        input_features,\n",
    "        hidden_size=HIDDEN_SIZE,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        output_size=1,\n",
    "        dropout_prob=DROPOUT,\n",
    "    )\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_out = model(X_pred_t)\n",
    "        pred_scaled = pred_out.detach().cpu().numpy()\n",
    "        pred = scaler_y.inverse_transform(pred_scaled)[0][0]\n",
    "\n",
    "    result = {\n",
    "        \"dataset_idx\": dataset_idx,\n",
    "        \"ticker\": ticker_value,\n",
    "        \"best_val_loss\": best_window_loss,\n",
    "        \"best_val_r2\": best_window_r2,\n",
    "        \"best_window_size\": best_window_size,\n",
    "        \"prediction_first_row\": float(pred),\n",
    "    }\n",
    "\n",
    "    if wandb_run is not None:\n",
    "        wandb_run.log(\n",
    "            {\n",
    "                \"dataset_best_val_loss\": float(best_window_loss),\n",
    "                \"dataset_best_val_r2\": float(best_window_r2) if not np.isnan(best_window_r2) else np.nan,\n",
    "                \"dataset_best_window_size\": int(best_window_size),\n",
    "                \"dataset_prediction_first_row\": float(pred),\n",
    "                \"dataset_idx\": dataset_idx,\n",
    "                \"ticker\": str(ticker_value),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return result, f\"Dataset {dataset_idx}: done (best loss={best_window_loss:.6f}, best R2={best_window_r2:.4f}, pred={pred:.4f}).\"\n",
    "\n",
    "\n",
    "wandb_run = None\n",
    "if USE_WANDB:\n",
    "    if wandb is None:\n",
    "        print(\"wandb is not installed. Install it with: pip install wandb\")\n",
    "    else:\n",
    "        try:\n",
    "            wandb_run = wandb.init(\n",
    "                project=WANDB_PROJECT,\n",
    "                entity=WANDB_ENTITY,\n",
    "                name=WANDB_RUN_NAME,\n",
    "                config={\n",
    "                    \"hidden_size\": HIDDEN_SIZE,\n",
    "                    \"num_layers\": NUM_LAYERS,\n",
    "                    \"dropout\": DROPOUT,\n",
    "                    \"epochs\": EPOCHS,\n",
    "                    \"learning_rate\": LEARNING_RATE,\n",
    "                    \"weight_decay\": WEIGHT_DECAY,\n",
    "                    \"window_size\": WINDOW_SIZE,\n",
    "                    \"target_col\": target_col,\n",
    "                    \"num_datasets\": len(data),\n",
    "                },\n",
    "            )\n",
    "            print(f\"wandb tracking enabled: project={WANDB_PROJECT}, run={WANDB_RUN_NAME}\")\n",
    "        except Exception as e:\n",
    "            print(f\"wandb init failed, continuing without tracking: {e}\")\n",
    "            wandb_run = None\n",
    "\n",
    "all_results = []\n",
    "logs = []\n",
    "start = time.time()\n",
    "\n",
    "for idx, df in tqdm(enumerate(data), smoothing=0):\n",
    "    result, msg = train_single_dataframe(df, idx, wandb_run=wandb_run)\n",
    "    logs.append(msg)\n",
    "    if result is not None:\n",
    "        all_results.append(result)\n",
    "\n",
    "print(\"\\n\".join(logs))\n",
    "\n",
    "if all_results:\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "\n",
    "    avg_val_loss = results_df[\"best_val_loss\"].mean()\n",
    "    avg_val_r2 = results_df[\"best_val_r2\"].mean(skipna=True)\n",
    "\n",
    "    print(\"\\n===== Aggregate Metrics =====\")\n",
    "    print(f\"Models trained: {len(results_df)} / {len(data)}\")\n",
    "    print(f\"Average best validation loss: {avg_val_loss:.6f}\")\n",
    "    print(f\"Average best validation R^2: {avg_val_r2:.4f}\")\n",
    "\n",
    "    print(\"\\n===== Predictions for First Row (per dataset) =====\")\n",
    "    display(results_df[[\"dataset_idx\", \"ticker\", \"prediction_first_row\", \"best_val_loss\", \"best_val_r2\", \"best_window_size\"]])\n",
    "\n",
    "    if wandb_run is not None:\n",
    "        wandb_run.log(\n",
    "            {\n",
    "                \"aggregate_models_trained\": int(len(results_df)),\n",
    "                \"aggregate_total_datasets\": int(len(data)),\n",
    "                \"aggregate_avg_best_val_loss\": float(avg_val_loss),\n",
    "                \"aggregate_avg_best_val_r2\": float(avg_val_r2) if not np.isnan(avg_val_r2) else np.nan,\n",
    "            }\n",
    "        )\n",
    "        pred_table = wandb.Table(dataframe=results_df)\n",
    "        wandb_run.log({\"predictions_table\": pred_table})\n",
    "else:\n",
    "    print(\"No models were successfully trained.\")\n",
    "\n",
    "runtime_seconds = time.time() - start\n",
    "print(f\"\\nTotal runtime: {runtime_seconds:.2f} seconds\")\n",
    "\n",
    "if wandb_run is not None:\n",
    "    wandb_run.log({\"runtime_seconds\": float(runtime_seconds)})\n",
    "    wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4406c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
